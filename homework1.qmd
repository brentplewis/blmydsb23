---
title: "Homerwork 1"
author: "Brent Lewis"
date: 2023-05-14
format: 
  docx: default
  html:
    toc: true
    toc_float: true
    code-fold: true
editor: visual
---

```{r}
#| label: load-libraries
#| echo: false # This option disables the printing of code (only output is displayed).
#| message: false
#| warning: false

library(tidyverse)
library(nycflights13)
library(skimr)

```

# Data Manipulation

## Problem 1: Use logical operators to find flights that:

```         
-   Had an arrival delay of two or more hours (\> 120 minutes)
-   Flew to Houston (IAH or HOU)
-   Were operated by United (`UA`), American (`AA`), or Delta (`DL`)
-   Departed in summer (July, August, and September)
-   Arrived more than two hours late, but didn't leave late
-   Were delayed by at least an hour, but made up over 30 minutes in flight
```

```{r}
#| label: problem-1

# Had an arrival delay of two or more hours (> 120 minutes)
library(tidyverse)
library(nycflights13)
library(skimr)

delay_2_hr <- flights %>% 
  filter(arr_delay>"120")

# Flew to Houston (IAH or HOU)
houston_flights <- flights %>% 
  filter(dest == "HOU"| dest =="IAH")

houston_flights

# Were operated by United (`UA`), American (`AA`), or Delta (`DL`)
UA_AA_DL_operated_flights <- flights %>% 
  filter(carrier=="UA"|carrier=="AA"|carrier=="DL")

UA_AA_DL_operated_flights

# Departed in summer (July, August, and September)
summer_flights <-flights %>% 
  filter(month=="7"|month=="8"|month=="9")
summer_flights
  
# Arrived more than two hours late, but didn't leave late
two_hours_late <-flights %>% 
  filter(arr_delay >120) %>% 
  filter(dep_delay <= 0)


# Were delayed by at least an hour, but made up over 30 minutes in flight
made_up_time <- flights %>% 
  filter(dep_delay >= 60) %>% 
  filter(dep_delay-arr_delay>30)

made_up_time
```

## Problem 2: What months had the highest and lowest proportion of cancelled flights? Interpret any seasonal patterns. To determine if a flight was cancelled use the following code

<!-- -->

```         
flights %>% 
  filter(is.na(dep_time)) 
```

```{r}
#| label: problem-2

# What months had the highest and lowest % of cancelled flights?

# Total number of cancelled flights, summarised as a new column and saved as a new tibble
cancelled_flights<- flights %>% 
  filter(is.na(dep_time)) %>% 
  group_by(month) %>% 
  summarise(cancelled_flights_count = n())

cancelled_flights

# Total number of flights overall in dataset, summarised as a new column and saved as a new tibble
total_flights<- flights %>% 
  group_by(month) %>% 
  summarise(total_flights_count = n())

total_flights

# Proportion of total flights that are cancelled, calculated by left joining the cancelled_flights tibble to the total_flights tibble by the "month" variable (no issue with lost rows, since both tibbles have the same number of rows), creating a new "prop" variable to calculate the proportion of cancelled flights at each month and arranging from largest proportion to smallest

cancelled_flights_prop <-total_flights %>% 
  left_join(cancelled_flights, by = "month") %>% 
  mutate (prop = cancelled_flights_count / total_flights_count) %>% 
  arrange(desc(prop))

cancelled_flights_prop

# Intepretation: No months show especially high proportions of cancelled flights; February is the largest at 5%. We could infer that the higher proportions of cancelled flights towards the end of the calendar and academic/financial yeard are somehow related to travellers' changes of plans around holiday periods.
```

## Problem 3: What plane (specified by the `tailnum` variable) traveled the most times from New York City airports in 2013? Please `left_join()` the resulting table with the table `planes` (also included in the `nycflights13` package).

For the plane with the greatest number of flights and that had more than 50 seats, please create a table where it flew to during 2013.

```{r}

skim(flights)

# This code assumes that Newark Airport is not a New York City airport  

# Create a new dataframe
frequent_flyer<-flights %>%
# Filter in only LGA and JFK (i.e. exclude EWR)
  filter(origin %in% c("LGA","JFK")) %>%
# Group by tail number (since we are counting flights on the basis of tail number)
  group_by(tailnum) %>% 
# Generate a new column called tail_num_flights, which is just a count of the total flights per each distinct tail number in the frequent_flyer dataframe
  summarise(tail_num_flights = n()) %>%
# Arrange in descending order (i.e. most flights at the top) 
  arrange(desc(tail_num_flights))

print(frequent_flyer)

# Left join the frequent_flyer datafram to planes dataframe on the basis of tail number
planes_updated <-planes %>% 
  left_join(frequent_flyer, by = "tailnum") %>% 
  arrange(desc(tail_num_flights))

print(planes_updated)
```

## Problem 4: The `nycflights13` package includes a table (`weather`) that describes the weather during 2013. Use that table to answer the following questions:

```         
-   What is the distribution of temperature (`temp`) in July 2013? Identify any important outliers in terms of the `wind_speed` variable.
-   What is the relationship between `dewp` and `humid`?
-   What is the relationship between `precip` and `visib`?
```

```{r}
# Create a new tibble called july_weather by filtering the only for month 7 (i.e. July) and filtering out non-recorded wind_speed observations 
july_weather <- filter(weather, month == 7 & !is.na(wind_speed))

# Create new tibbles for median, mean and standard deviation of the july_weather temp and wind_speed variables. We will use these later
median_temp <- median(july_weather$temp)
mean_temp <- mean(july_weather$temp)
sd_temp <- sd(july_weather$temp)

median_wind_speed <- median(july_weather$wind_speed)
mean_wind_speed <- mean(july_weather$wind_speed)
sd_wind_speed <- sd(july_weather$wind_speed)

# To show the distribution of temperatures in july_weather, create a density plot for temperatures, with temperature on the x-axis 
ggplot(july_weather, aes(x = temp, y = ..density..)) +
  geom_density(fill = "skyblue", color = "black") +
# Add dashed vertical lines for the median and mean temperatures
  geom_vline(aes(xintercept = median_temp), color = "blue", linetype = "dashed", size = 1) +
  geom_vline(aes(xintercept = mean_temp), color = "green", linetype = "dashed", size = 1) +
#Write notes for each of the mean, median and standard deviation of temperature and line them up according to to the placement of the mean_temp recording on the x-axis
  annotate("text", x = mean_temp + 11, y = 0.04, label = paste("Median =",round(median_temp,2)), color = "blue", vjust = -1) +
  annotate("text", x = mean_temp + 11, y = 0.035, label = paste("Mean =",round(mean_temp,2)), color = "green", vjust = -1) +
   annotate("text", x = mean_temp +11, y = 0.03, label = paste("SD =", round(sd_temp, 2)), color = "red", vjust = -1) +
# Label the x-axis "Temperature" and the y-axis "Frequency") 
  labs(x = "Temperature", y = "Frequency") +
# Insert a title
  ggtitle("The average temperature in July was 80 degrees") +
  theme_minimal() +
# Insert appropriate margins to expand or contract the graph size
  theme(plot.margin = margin(0.8, 0.8, 0, 0.8, "cm"))

# To identify outliers, create a box plot of the wind_speed variable. Don't include anything on the x-axis, since we only need to show range in one variable and not necessarily over a specific period
ggplot(july_weather, aes(x = "", y = wind_speed)) +
  geom_boxplot(fill = "skyblue", color = "black") +
# To show outliers, add a geom_point that filters in (from the wind_speed variable of the july_weather dataframe) only the wind_speed observations in the 99.7th or 0.3rd percentiles (i.e. ~ 3 standard deviations from the mean) and colour these red to make them distinct
  geom_point(data = filter(july_weather, wind_speed > quantile(wind_speed, 0.997) |
                                            wind_speed < quantile(wind_speed, 0.003)),
             aes(x = 1, y = wind_speed), color = "red", shape = 16, size = 3) +
  labs(x = "", y = "Wind Speed") +
# Apply the same annotations as for the temp graph above
  annotate("text", x = 1, y = mean_wind_speed + 2, label = paste("Mean:", round(mean_wind_speed, 2)),
           color = "green", size = 3, hjust = 0, vjust = 0) +
  annotate("text", x = 1, y = mean_wind_speed + 1, label = paste("SD:", round(sd_wind_speed, 2)),
           color = "green", size = 3, hjust = 0, vjust = 0) +
# Apply a title that provides the conclusion
  ggtitle("Wind speed in July was mostly between 5 and 15 mph") +
  theme_minimal()

# To show the relationship between the humidity and dew point measure, first create a new tibble recording the correlation coefficient of the humid and dewp variables in the weather dataframe (note that this question doesn't ask us to filter specifically for July).

correlation_humid_dewp <- cor(weather$humid, weather$dewp, use = "complete.obs") 

# Use only complete observations (i.e. nothing recorded as "NA")

# Map this relationship using a scatter plot, with humidity on the x-axis and dew point measurement on the y-axis
ggplot(weather, aes(x = humid, y = dewp)) +
# Since some of the points overlap, set the alpha (i.e. transparency) slightly above half (0.7 should do) to show overlapped points that don't distort the image
  geom_point(color = "skyblue", alpha = 0.7) +
# Insert a line of best fit to demonstrate the relationship between the variables
  geom_smooth(method = "lm", color = "red", se = FALSE) +
# Insert an annotation to show the correlation coefficient
  geom_text(x = max(weather$humid, na.rm = TRUE), y = min(weather$dewp, na.rm = TRUE), label = paste("Correlation:", round(correlation_humid_dewp, 4)), hjust = 1, vjust = 0, color = "black", size = 4) +
#Insert axis labels 
   labs(x = "Humidity", y = "Dew Point") +
# Insert a title
  ggtitle("Dew point tends to rise as humidity rises") +
  theme_minimal()


# To show the relationship between precipitation and visibility, perform the exact same operation as for humidity and precipitation, changing the variables as necessary
correlation_precip_visib <- cor(weather$precip, weather$visib, use = "complete.obs")

ggplot(weather, aes(x = precip, y = visib)) +
  geom_point(color = "skyblue", alpha = 0.7) +
  geom_smooth(method = "lm", color = "red", se = FALSE) +
  geom_text(x = max(weather$precip, na.rm = TRUE), y = min(weather$visib, na.rm = TRUE),
            label = paste("Correlation:", round(correlation_precip_visib, 4)), hjust = 1.5, vjust = -2,
            color = "black", size = 4) +
  labs(x = "Precipitation", y = "Visibility") +
  ggtitle("Visibility tends to fall as precipitation rises, but the relationship is not strong") +
  theme_minimal()+
# Set the lower limit on the y-axis to zero so ensure the image isn't distorted.
  ylim(0,NA)

# Notably, the graph doesn't show a particularly compelling relationship between the two variables, in spite of the correlation coefficient, which shows some relationship. This could be because the visibility variable is divided into different bins
```

## Problem 5: Use the `flights` and `planes` tables to answer the following questions:

```         
-   How many planes have a missing date of manufacture?
-   What are the five most common manufacturers?
-   Has the distribution of manufacturer changed over time as reflected by the airplanes flying from NYC in 2013? (Hint: you may need to use case_when() to recode the manufacturer name and collapse rare vendors into a category called Other.)
```

```{r}
# To count how many planes have a missing date of manufacture, simply filter the planes year (of manufacture) variable in the planes dataframe for all "NA" results
planes %>% 
  filter(is.na(year)) %>% 
  count()

# To find the five most common manufacturers, create a new dataframe from planes which is grouped by manufacturer (since we will be sorting by this variable)
manufacturer_count <- planes %>% 
  group_by(manufacturer) %>%
# Recode the observations in the manufacturer column to align the spelling of inconsistentently recorded manufacturer titles
  mutate(manufacturer=recode(manufacturer,"AIRBUS INDUSTRIE" = "AIRBUS","MCDONNELL DOUGLAS AIRCRAFT CO" = "MCDONNELL DOUGLAS","MCDONNELL DOUGLAS CORPORATION" = "MCDONNELL DOUGLAS")) %>% 
# Create another column counting the number of manufacturers
  summarise(count=n()) %>% 
# Arrange the tibble in descending order by this count 
   arrange(desc(count))

# Using the manufacturer_count tibble we just created, create a list of the top
top_manufacturers <- top_n(manufacturer_count, 5, count)

print(top_manufacturers)

# We can see that Boeing and Airbus are the leading manufacturers


# To show how the distribution of manufacturers has changed over time as reflected by the airplanes flying from NYC in 2013, we will show how this distribution changes on a day-by-day basis for 2013

# First import the lubridate library to allow us to manipulate date settings in the flights library
library(lubridate)

# Then create a new variable in this tibble called day_of_year that records the specific day of the year (between 1 and 365) based on the available year, month and day variables already provided
flights_updated <- flights %>%
  mutate(day_of_year = yday(ymd(paste(year, month, day, sep = "-"))))

# Using this new tibble, filter out cancelled flights
completed_flights<-flights_updated %>% 
  filter(!is.na(dep_time))

# Right join the planes dataframe to the completed_flights data frame, using a right join so that individual flight records are not lost. In doing this, we select only the tailnum, manufacturer and year variables form the planes tibble and change the title of year to build_year to avoid a clash with the existing variable in flights
flights_with_manufacturers <-right_join(completed_flights,planes %>% 
  select(tailnum, manufacturer, build_year=year) %>% 
# Perform the same renaming mutation as above
    mutate(manufacturer=recode(manufacturer,"AIRBUS INDUSTRIE" = "AIRBUS","MCDONNELL DOUGLAS AIRCRAFT CO" = "MCDONNELL DOUGLAS","MCDONNELL DOUGLAS CORPORATION" = "MCDONNELL DOUGLAS")), by = "tailnum")

# From this tibble, create another tibble that mutates all observations in the manufacturer variable. By referring to the top_manufacturers list we created above, we identify anything that this not in that list as "Other"
updated_flights_with_manufacturers <- flights_with_manufacturers %>%
  mutate(manufacturer = case_when(
    manufacturer %in% top_manufacturers$manufacturer ~ manufacturer,
    TRUE ~ "Other")) %>% 
# Group by day_of_year first and then by manufacturer, since we will be sorting by both in that order, and provide a count of each flight
  group_by(day_of_year,manufacturer) %>% 
  summarise(count=n())

print(updated_flights_with_manufacturers)

# Plot this tibble as an area graph, with the day of the year on the x-axis showing how the distribution of flights has changed on a daily basis throughout 2013 among the manufacturers
ggplot(updated_flights_with_manufacturers, aes(x = day_of_year, y = count, fill = manufacturer, group = manufacturer)) +
  geom_area() +
  labs(x = "Day of year (out of 365)", y = "No. flights") +
  theme_minimal()
```

## Problem 6: Use the `flights` and `planes` tables to answer the following questions:

```         
-   What is the oldest plane (specified by the tailnum variable) that flew from New York City airports in 2013?
-   How many airplanes that flew from New York City are included in the planes table?
```

```{r}
# To see the oldest plane, using the flights_with_manufacturers tibble we created earlier, filter out all results where no build year is recorded
oldest_plane <- flights_with_manufacturers %>%
  filter(!is.na(build_year)) %>%
# Then sort by build year (ascending, so oldest first)
  arrange(build_year) %>% 
# Then take only the first result
  slice(1)

# Print out only the tailnum column from this resulting tibble
print(oldest_plane["tailnum"])


# To see how many airplanes that flew from NYC are included in the planes table, first create a new tibble from the flights_with_manufacturers tibble we created earlier
total_distinct_planes<-flights_with_manufacturers %>% 
# Filter out non-recored build years and tail numbers 
  filter(!is.na(build_year)&!is.na(tailnum)) %>%
# Record only distinct tail numbers (i.e. don't permit duplicates)
  distinct(tailnum) %>% 
# Take a count of the total number of rows
  summarise(total_distinct_planes=n())

print(total_distinct_planes)

```

## Problem 7: Use the `nycflights13` to answer the following questions:

```         
-   What is the median arrival delay on a month-by-month basis in each airport?
-   For each airline, plot the median arrival delay for each month and origin airport.
```

```{r}

# To find the median arrival delay on a month-by-month basis in each airport, first find the median arrival delay from the flights table
median_arrival_delay <- flights %>%
# Filter out cancelled flights
  filter(!is.na(dep_time)) %>%
# Group by month and then destination, since we are sorting by these variables
  group_by(month, dest) %>%
# Create a new column capturing the median arrival delay and filtering out non-recorded results
  summarise(median__arr_delay = median(arr_delay, na.rm = TRUE)) %>%
  arrange(dest, month)

print(median_arrival_delay)

# The below is another way of arranging this data by grouping by month
flights %>%
  filter(!is.na(arr_delay)) %>%
  group_by(month, dest) %>%
  summarise(median_arr_delay = median(arr_delay, na.rm = TRUE)) %>%
  arrange(month, dest)

# To plot the median arrival delay for each month and origin airport, first filter out all results where no arrival delay observation is recorded
flights %>%
  filter(!is.na(arr_delay)) %>%
# Group by the variables by which we will be arranging the data 
  group_by(origin, month, carrier) %>%
# Calculate the median arrival delay in the same way as above
  summarise(median_arr_delay = median(arr_delay, na.rm = TRUE)) %>%
# Plot the results on a scatter plot and facet wrap for origin airport for simplicity, with different colours for each carrier and each graph recording the months on the x-axis
  ggplot() +
  geom_point(aes(x = factor(month), y = median_arr_delay, color = carrier)) +
  facet_wrap(vars(origin), nrow = 2, scales = "free", labeller = label_both) +
  labs(x = "Month", y = "Median Arrival Delay", color = "Carrier") +
  ggtitle("Median Arrival Delay by Month for Each Airport and Carrier") +
  theme_minimal()
```

## Problem 8: Let's take a closer look at what carriers service the route to San Francisco International (SFO). Join the `flights` and `airlines` tables and count which airlines flew the most to SFO. Produce a new dataframe, `fly_into_sfo` that contains three variables: the `name` of the airline, e.g., `United Air Lines Inc.` not `UA`, the count (number) of times it flew to SFO, and the `percent` of the trips that that particular airline flew to SFO.

```{r}
fly_into_sfo<- flights %>%
# Left join the airlines tibble to the flights tibble by the carrier variable
  left_join(airlines,by="carrier") %>% 
# Filter in only SFO as the destination variable
  filter(dest == "SFO") %>%
# Group by name, since the new dataframe will count the number of flights for each name 
  group_by(name) %>%
# Count the number of flights for each name, recording this as "count"
  summarise(count = n()) %>%
# Create a new column that records the count of each airline as a percentage of total flights to SFO
  mutate(percent_to_sfo = count / sum(count) * 100)

fly_into_sfo
```

And here is some bonus ggplot code to plot your dataframe

```{r}
#| label: ggplot-flights-toSFO
#| message: false
#| warning: false

fly_into_sfo %>% 
  
  # sort 'name' of airline by the numbers it times to flew to SFO
  mutate(name = fct_reorder(name, count)) %>% 
  
  ggplot() +
  
  aes(x = count, 
      y = name) +
  
  # a simple bar/column plot
  geom_col() +
  
  # add labels, so each bar shows the % of total flights 
  geom_text(aes(label = percent),
             hjust = 1, 
             colour = "white", 
             size = 5)+
  
  # add labels to help our audience  
  labs(title="Which airline dominates the NYC to SFO route?", 
       subtitle = "as % of total flights in 2013",
       x= "Number of flights",
       y= NULL) +
  
  theme_minimal() + 
  
  # change the theme-- i just googled those , but you can use the ggThemeAssist add-in
  # https://cran.r-project.org/web/packages/ggThemeAssist/index.html
  
  theme(#
    # so title is left-aligned
    plot.title.position = "plot",
    
    # text in axes appears larger        
    axis.text = element_text(size=12),
    
    # title text is bigger
    plot.title = element_text(size=18)
      ) +

  # add one final layer of NULL, so if you comment out any lines
  # you never end up with a hanging `+` that awaits another ggplot layer
  NULL
 
 
```

## Problem 9: Let's take a look at cancellations of flights to SFO. We create a new dataframe `cancellations` as follows

```{r}

cancellations <- flights %>% 
  
  # just filter for destination == 'SFO'
  filter(dest == 'SFO') %>% 
  
  # a cancelled flight is one with no `dep_time` 
  filter(is.na(dep_time))


# First I would create a new dataframe that filters for only Newark and JFK as departure destinations, or filters out Laguardia. I would group this by month and then carrier. Then I would generate a geom_bar plot facet wrapped first by origin and then by carrier

```

I want you to think how we would organise our data manipulation to create the following plot. No need to write the code, just explain in words how you would go about it.

![](images/sfo-cancellations.png)

## Problem 10: On your own -- Hollywood Age Gap

The website <https://hollywoodagegap.com> is a record of *THE AGE DIFFERENCE IN YEARS BETWEEN MOVIE LOVE INTERESTS*. This is an informational site showing the age gap between movie love interests and the data follows certain rules:

-   The two (or more) actors play actual love interests (not just friends, coworkers, or some other non-romantic type of relationship)
-   The youngest of the two actors is at least 17 years old
-   No animated characters

The age gaps dataset includes "gender" columns, which always contain the values "man" or "woman". These values appear to indicate how the characters in each film identify and some of these values do not match how the actor identifies. We apologize if any characters are misgendered in the data!

The following is a data dictionary of the variables used

| variable            | class     | description                                                                                             |
|:-----------|:-----------|:----------------------------------------------|
| movie_name          | character | Name of the film                                                                                        |
| release_year        | integer   | Release year                                                                                            |
| director            | character | Director of the film                                                                                    |
| age_difference      | integer   | Age difference between the characters in whole years                                                    |
| couple_number       | integer   | An identifier for the couple in case multiple couples are listed for this film                          |
| actor_1\_name       | character | The name of the older actor in this couple                                                              |
| actor_2\_name       | character | The name of the younger actor in this couple                                                            |
| character_1\_gender | character | The gender of the older character, as identified by the person who submitted the data for this couple   |
| character_2\_gender | character | The gender of the younger character, as identified by the person who submitted the data for this couple |
| actor_1\_birthdate  | date      | The birthdate of the older member of the couple                                                         |
| actor_2\_birthdate  | date      | The birthdate of the younger member of the couple                                                       |
| actor_1\_age        | integer   | The age of the older actor when the film was released                                                   |
| actor_2\_age        | integer   | The age of the younger actor when the film was released                                                 |

```{r}

age_gaps <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2023/2023-02-14/age_gaps.csv')


```

How would you explore this data set? Here are some ideas of tables/ graphs to help you with your analysis

-   How is `age_difference` distributed? What's the 'typical' `age_difference` in movies?

-   The `half plus seven\` rule. Large age disparities in relationships carry certain stigmas. One popular rule of thumb is the [half-your-age-plus-seven](https://en.wikipedia.org/wiki/Age_disparity_in_sexual_relationships#The_.22half-your-age-plus-seven.22_rule) rule. This rule states you should never date anyone under half your age plus seven, establishing a minimum boundary on whom one can date. In order for a dating relationship to be acceptable under this rule, your partner's age must be:

$$\frac{\text{Your age}}{2} + 7 \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\< \text{Partner Age} \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\< (\text{Your age} - 7) \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\* 2$$
How frequently does this rule apply in this dataset?

-   Which movie has the greatest number of love interests?
-   Which actors/ actresses have the greatest number of love interests in this dataset?
-   Is the mean/median age difference staying constant over the years (1935 - 2022)?
-   How frequently does Hollywood depict same-gender love interests?

# Deliverables

There is a lot of explanatory text, comments, etc. You do not need these, so delete them and produce a stand-alone document that you could share with someone. Render the edited and completed Quarto Markdown (qmd) file as a Word document (use the "Render" button at the top of the script editor window) and upload it to Canvas. You must be commiting and pushing tour changes to your own Github repo as you go along.

# Details

-   Who did you collaborate with: TYPE NAMES HERE
-   Approximately how much time did you spend on this problem set: ANSWER HERE
-   What, if anything, gave you the most trouble: ANSWER HERE

**Please seek out help when you need it,** and remember the [15-minute rule](https://mam2022.netlify.app/syllabus/#the-15-minute-rule){target="\_blank"}. You know enough R (and have enough examples of code from class and your readings) to be able to do this. If you get stuck, ask for help from others, post a question on Slack-- and remember that I am here to help too!

> As a true test to yourself, do you understand the code you submitted and are you able to explain it to someone else?

# Rubric

13/13: Problem set is 100% completed. Every question was attempted and answered, and most answers are correct. Code is well-documented (both self-documented and with additional comments as necessary). Used tidyverse, instead of base R. Graphs and tables are properly labelled. Analysis is clear and easy to follow, either because graphs are labeled clearly or you've written additional text to describe how you interpret the output. Multiple Github commits. Work is exceptional. I will not assign these often.

8/13: Problem set is 60--80% complete and most answers are correct. This is the expected level of performance. Solid effort. Hits all the elements. No clear mistakes. Easy to follow (both the code and the output). A few Github commits.

5/13: Problem set is less than 60% complete and/or most answers are incorrect. This indicates that you need to improve next time. I will hopefully not assign these often. Displays minimal effort. Doesn't complete all components. Code is poorly written and not documented. Uses the same type of plot for each graph, or doesn't use plots appropriate for the variables being analyzed. No Github commits.
